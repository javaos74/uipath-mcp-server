"""Chainlit MCP Client Application"""
import chainlit as cl
from openai import AsyncOpenAI
import json
from typing import List, Dict, Any, Optional
import logging
import asyncio

from config import config
from mcp_client import MCPClientManager, Tool

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Global MCP manager
mcp_manager: Optional[MCPClientManager] = None


async def logging_notification_handler(server_name: str, params) -> None:
    """Handle logging notifications from MCP servers"""
    # Send log messages to Chainlit UI
    level_emoji = {
        "debug": "ğŸ”",
        "info": "â„¹ï¸",
        "warning": "âš ï¸",
        "error": "âŒ",
        "critical": "ğŸš¨",
    }
    emoji = level_emoji.get(params.level, "ğŸ“")
    
    # Only show warning and above in UI
    if params.level in ["warning", "error", "critical"]:
        await cl.Message(
            content=f"{emoji} **[{server_name}]** {params.data}",
            author=server_name,
        ).send()
    
    # Always log to Python logger
    logger.info(f"[{server_name}] {params.level}: {params.data}")


async def message_notification_handler(server_name: str, message: Any) -> None:
    """Handle general notifications from MCP servers"""
    from mcp import types
    
    if isinstance(message, types.ServerNotification):
        notification_type = type(message.root).__name__
        logger.debug(f"[{server_name}] Notification: {notification_type}")
        
        # Handle specific notification types
        if isinstance(message.root, types.ResourceUpdatedNotification):
            logger.info(f"[{server_name}] Resource updated: {message.root.params.uri}")
        elif isinstance(message.root, types.ResourceListChangedNotification):
            logger.info(f"[{server_name}] Resource list changed")
        elif isinstance(message.root, types.PromptListChangedNotification):
            logger.info(f"[{server_name}] Prompt list changed")
        elif isinstance(message.root, types.ToolListChangedNotification):
            logger.info(f"[{server_name}] Tool list changed")
    elif isinstance(message, Exception):
        logger.error(f"[{server_name}] Exception: {message}")


async def initialize_mcp_servers():
    """Initialize all MCP servers from config"""
    global mcp_manager
    
    if mcp_manager is None:
        mcp_manager = MCPClientManager(
            logging_callback=logging_notification_handler,
            message_handler=message_notification_handler,
        )
    
    # Initialize servers from config
    for server_name, server_config in config.mcpServers.items():
        try:
            await mcp_manager.add_server(server_name, server_config.model_dump())
            logger.info(f"Initialized server: {server_name}")
        except Exception as e:
            logger.error(f"Failed to initialize server {server_name}: {e}")


@cl.on_chat_start
async def start():
    """Initialize chat session"""
    
    # Check if this is first time setup
    if not config.openai_api_key:
        await show_settings_form()
        return
    
    # Initialize OpenAI client
    client = AsyncOpenAI(api_key=config.openai_api_key)
    cl.user_session.set("client", client)
    
    # Initialize MCP servers
    init_msg = cl.Message(content="ğŸ”„ MCP ì„œë²„ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘...")
    await init_msg.send()
    
    try:
        await initialize_mcp_servers()
        
        # Get available tools
        all_tools = await mcp_manager.list_all_tools()
        total_tools = sum(len(tools) for tools in all_tools.values())
        
        if all_tools:
            init_msg.content = f"âœ… MCP ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ! {len(all_tools)}ê°œ ì„œë²„, {total_tools}ê°œ ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥"
        else:
            init_msg.content = "â„¹ï¸ ì—°ê²°ëœ MCP ì„œë²„ê°€ ì—†ìŠµë‹ˆë‹¤. `/servers` ëª…ë ¹ìœ¼ë¡œ ì„œë²„ë¥¼ ì¶”ê°€í•˜ì„¸ìš”."
        await init_msg.update()
    except Exception as e:
        init_msg.content = f"âš ï¸ MCP ì„œë²„ ì´ˆê¸°í™” ì¤‘ ì¼ë¶€ ì˜¤ë¥˜ ë°œìƒ. `/servers`ë¡œ ì„œë²„ë¥¼ í™•ì¸í•˜ì„¸ìš”."
        await init_msg.update()
        logger.error(f"MCP initialization error: {e}")
    
    # Store message history
    cl.user_session.set("message_history", [])
    
    # Welcome message
    welcome_msg = """
# ğŸ¤– MCP Clientì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!

ì´ í´ë¼ì´ì–¸íŠ¸ëŠ” MCP (Model Context Protocol) ì„œë²„ì™€ í†µì‹ í•˜ë©° OpenAIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

## ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:
- `/settings` - OpenAI API í‚¤ ì„¤ì •
- `/servers` - MCP ì„œë²„ ê´€ë¦¬
- `/tools` - ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ë³´ê¸°
- `/new` - ìƒˆ ì±„íŒ… ì‹œì‘
- ì¼ë°˜ ë©”ì‹œì§€ - AIì™€ ëŒ€í™”í•˜ê¸°

íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì²˜ë¦¬í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
"""
    await cl.Message(content=welcome_msg).send()


@cl.on_chat_end
async def end():
    """Clean up when chat ends"""
    global mcp_manager
    if mcp_manager:
        await mcp_manager.cleanup_all()
        logger.info("Cleaned up MCP servers")


@cl.on_message
async def main(message: cl.Message):
    """Handle incoming messages"""
    
    # Handle commands
    if message.content.startswith("/"):
        await handle_command(message)
        return
    
    # Get OpenAI client
    client = cl.user_session.get("client")
    if not client:
        await cl.Message(
            content="âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•˜ê³  ì¬ì‹œì‘í•´ì£¼ì„¸ìš”."
        ).send()
        return
    
    # Handle file uploads
    files_content = ""
    if message.elements:
        files_content = await process_uploaded_files(message.elements)
    
    # Get message history
    message_history = cl.user_session.get("message_history", [])
    
    # Add user message to history
    user_message = message.content
    if files_content:
        user_message += f"\n\n[ì—…ë¡œë“œëœ íŒŒì¼ ë‚´ìš©]\n{files_content}"
    
    message_history.append({
        "role": "user",
        "content": user_message
    })
    
    # Get available tools
    all_tools = await mcp_manager.list_all_tools()
    tools_for_openai = []
    tool_map = {}  # Map tool name to (server_name, tool)
    
    for server_name, tools in all_tools.items():
        for tool in tools:
            tools_for_openai.append(tool.to_openai_format())
            tool_map[tool.name] = (server_name, tool)
    
    # Prepare messages for OpenAI
    messages = message_history.copy()
    
    # Stream response from OpenAI
    msg = cl.Message(content="")
    await msg.send()
    
    try:
        # Call OpenAI with function calling
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            tools=tools_for_openai if tools_for_openai else None,
            tool_choice="auto" if tools_for_openai else None,
            temperature=0.7,
            stream=True
        )
        
        full_response = ""
        tool_calls = []
        current_tool_call = None
        
        async for chunk in response:
            delta = chunk.choices[0].delta
            
            # Handle content
            if delta.content:
                full_response += delta.content
                await msg.stream_token(delta.content)
            
            # Handle tool calls
            if delta.tool_calls:
                for tc_chunk in delta.tool_calls:
                    if tc_chunk.index is not None:
                        # New tool call or continuing existing one
                        while len(tool_calls) <= tc_chunk.index:
                            tool_calls.append({
                                "id": "",
                                "type": "function",
                                "function": {"name": "", "arguments": ""}
                            })
                        
                        if tc_chunk.id:
                            tool_calls[tc_chunk.index]["id"] = tc_chunk.id
                        
                        if tc_chunk.function:
                            if tc_chunk.function.name:
                                tool_calls[tc_chunk.index]["function"]["name"] = tc_chunk.function.name
                            if tc_chunk.function.arguments:
                                tool_calls[tc_chunk.index]["function"]["arguments"] += tc_chunk.function.arguments
        
        # If no content was streamed, update the message
        if not full_response and not tool_calls:
            await msg.update()
        elif full_response:
            await msg.update()
        
        # Handle tool calls
        if tool_calls:
            # Add assistant message with tool calls to history
            message_history.append({
                "role": "assistant",
                "content": full_response if full_response else None,
                "tool_calls": tool_calls
            })
            
            # Execute tools
            tool_results = []
            for tool_call in tool_calls:
                tool_name = tool_call["function"]["name"]
                tool_args = json.loads(tool_call["function"]["arguments"])
                
                if tool_name in tool_map:
                    server_name, tool = tool_map[tool_name]
                    
                    # Show tool execution message
                    tool_msg = cl.Message(
                        content=f"ğŸ”§ ë„êµ¬ ì‹¤í–‰ ì¤‘: `{tool_name}` (ì„œë²„: {server_name})"
                    )
                    await tool_msg.send()
                    
                    try:
                        result = await mcp_manager.execute_tool(
                            server_name,
                            tool_name,
                            tool_args
                        )
                        
                        result_str = json.dumps(result, ensure_ascii=False, indent=2)
                        tool_results.append({
                            "role": "tool",
                            "tool_call_id": tool_call["id"],
                            "content": result_str
                        })
                        
                        tool_msg.content = f"âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ: `{tool_name}`\n```json\n{result_str}\n```"
                        await tool_msg.update()
                    except Exception as e:
                        error_msg = f"ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"
                        tool_results.append({
                            "role": "tool",
                            "tool_call_id": tool_call["id"],
                            "content": error_msg
                        })
                        tool_msg.content = f"âŒ {error_msg}"
                        await tool_msg.update()
            
            # Add tool results to history
            message_history.extend(tool_results)
            
            # Get final response from OpenAI
            final_msg = cl.Message(content="")
            await final_msg.send()
            
            final_response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=message_history,
                temperature=0.7,
                stream=True
            )
            
            final_content = ""
            async for chunk in final_response:
                if chunk.choices[0].delta.content:
                    token = chunk.choices[0].delta.content
                    final_content += token
                    await final_msg.stream_token(token)
            
            await final_msg.update()
            
            # Add final response to history
            message_history.append({
                "role": "assistant",
                "content": final_content
            })
        else:
            # No tool calls, just add the response to history
            message_history.append({
                "role": "assistant",
                "content": full_response
            })
        
        cl.user_session.set("message_history", message_history)
        
    except Exception as e:
        logger.error(f"Error in chat completion: {e}")
        await cl.Message(content=f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}").send()


async def handle_command(message: cl.Message):
    """Handle special commands"""
    command = message.content.lower().strip()
    
    if command == "/settings":
        await show_settings_form()
    elif command == "/servers":
        await show_mcp_servers_list()
    elif command == "/tools":
        await show_tools()
    elif command == "/new":
        await start_new_chat()
    else:
        await cl.Message(content=f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {command}").send()


async def show_settings_form():
    """Show interactive settings form"""
    settings = cl.ChatSettings(
        [
            cl.input_widget.TextInput(
                id="openai_api_key",
                label="OpenAI API Key",
                initial=config.openai_api_key if config.openai_api_key else "",
                placeholder="sk-...",
                description="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            ),
        ]
    )
    await settings.send()
    
    # Show current MCP servers
    await show_mcp_servers_list()


async def show_mcp_servers_list():
    """Show list of MCP servers with management actions"""
    servers_text = "# ğŸ”Œ MCP ì„œë²„ ê´€ë¦¬\n\n"
    
    if config.mcpServers:
        for server_name, server_config in config.mcpServers.items():
            status = "âœ…" if server_config.enabled else "âŒ"
            servers_text += f"## {status} {server_name}\n"
            servers_text += f"- URL: `{server_config.url}`\n"
            servers_text += f"- Token: {'ì„¤ì •ë¨' if server_config.token else 'ë¯¸ì„¤ì •'}\n"
            servers_text += f"- Timeout: {server_config.timeout}ì´ˆ\n\n"
    else:
        servers_text += "ë“±ë¡ëœ ì„œë²„ê°€ ì—†ìŠµë‹ˆë‹¤.\n\n"
    
    servers_text += "ì•„ë˜ ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì„œë²„ë¥¼ ê´€ë¦¬í•˜ì„¸ìš”."
    
    actions = [
        cl.Action(
            name="add_server",
            value="add_server",
            payload={"action": "add_server"},
            label="â• ì„œë²„ ì¶”ê°€",
        ),
        cl.Action(
            name="refresh_servers",
            value="refresh",
            payload={"action": "refresh"},
            label="ğŸ”„ ìƒˆë¡œê³ ì¹¨",
        ),
    ]
    
    await cl.Message(content=servers_text, actions=actions).send()


async def show_settings():
    """Show settings dialog"""
    await show_settings_form()


@cl.on_settings_update
async def on_settings_update(settings: Dict[str, Any]):
    """Handle settings update"""
    logger.info(f"Settings updated: {settings}")
    
    # Update OpenAI API key
    if "openai_api_key" in settings and settings["openai_api_key"]:
        config.openai_api_key = settings["openai_api_key"]
        config.save_to_file()
        
        # Reinitialize OpenAI client
        client = AsyncOpenAI(api_key=config.openai_api_key)
        cl.user_session.set("client", client)
        
        await cl.Message(content="âœ… OpenAI API í‚¤ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!").send()
        
        # Initialize MCP servers if not already done
        if mcp_manager is None or not mcp_manager.servers:
            await initialize_mcp_servers()


@cl.action_callback("add_server")
async def on_add_server(action: cl.Action):
    """Handle add server action"""
    # Ask for server details
    res = await cl.AskUserMessage(
        content="ìƒˆ MCP ì„œë²„ì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”:",
        timeout=60,
    ).send()
    
    if not res:
        return
    
    server_name = res["output"].strip()
    if not server_name:
        await cl.Message(content="âŒ ì„œë²„ ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤.").send()
        return
    
    # Ask for URL
    res = await cl.AskUserMessage(
        content=f"**{server_name}** ì„œë²„ì˜ SSE ì—”ë“œí¬ì¸íŠ¸ URLì„ ì…ë ¥í•˜ì„¸ìš”:\nì˜ˆ: http://localhost:8000/sse",
        timeout=60,
    ).send()
    
    if not res:
        return
    
    server_url = res["output"].strip()
    if not server_url:
        await cl.Message(content="âŒ URLì´ í•„ìš”í•©ë‹ˆë‹¤.").send()
        return
    
    # Ask for token (optional)
    res = await cl.AskUserMessage(
        content="Bearer í† í°ì„ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­, ì—†ìœ¼ë©´ Enter):",
        timeout=60,
    ).send()
    
    server_token = res["output"].strip() if res and res["output"] else None
    
    # Add server to config
    from config import MCPServerConfig
    
    config.mcpServers[server_name] = MCPServerConfig(
        url=server_url,
        token=server_token if server_token else None,
        enabled=True,
    )
    config.save_to_file()
    
    await cl.Message(content=f"âœ… ì„œë²„ **{server_name}**ì´(ê°€) ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!").send()
    
    # Try to initialize the server
    try:
        await mcp_manager.add_server(server_name, config.mcpServers[server_name].model_dump())
        await cl.Message(content=f"âœ… ì„œë²„ **{server_name}** ì—°ê²° ì„±ê³µ!").send()
    except Exception as e:
        await cl.Message(content=f"âš ï¸ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {str(e)}\nì„¤ì •ì€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.").send()
    
    # Refresh server list
    await show_mcp_servers_list()


@cl.action_callback("refresh_servers")
async def on_refresh_servers(action: cl.Action):
    """Handle refresh servers action"""
    await show_mcp_servers_list()


async def show_tools():
    """Show available tools from all MCP servers"""
    msg = cl.Message(content="ğŸ” ë„êµ¬ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    await msg.send()
    
    all_tools = await mcp_manager.list_all_tools()
    
    if not all_tools:
        msg.content = "âŒ ì—°ê²°ëœ MCP ì„œë²„ê°€ ì—†ê±°ë‚˜ ë„êµ¬ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        await msg.update()
        return
    
    tools_text = "# ğŸ› ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬\n\n"
    
    for server_name, tools in all_tools.items():
        tools_text += f"## ì„œë²„: {server_name}\n\n"
        if tools:
            for tool in tools:
                tools_text += f"### {tool.name}\n"
                if tool.title:
                    tools_text += f"**{tool.title}**\n\n"
                tools_text += f"{tool.description}\n\n"
                
                if "properties" in tool.input_schema:
                    tools_text += "**ë§¤ê°œë³€ìˆ˜:**\n"
                    for param_name, param_info in tool.input_schema["properties"].items():
                        required = " (í•„ìˆ˜)" if param_name in tool.input_schema.get("required", []) else ""
                        tools_text += f"- `{param_name}`: {param_info.get('description', 'No description')}{required}\n"
                    tools_text += "\n"
        else:
            tools_text += "ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤.\n\n"
    
    msg.content = tools_text
    await msg.update()


async def start_new_chat():
    """Start a new chat session"""
    cl.user_session.set("message_history", [])
    await cl.Message(content="âœ¨ ìƒˆë¡œìš´ ì±„íŒ…ì„ ì‹œì‘í•©ë‹ˆë‹¤!").send()


async def process_uploaded_files(elements: List[Any]) -> str:
    """Process uploaded files"""
    files_content = []
    
    for element in elements:
        # Check if it's a file-like element
        if hasattr(element, 'path') and hasattr(element, 'name'):
            try:
                # Read file content
                with open(element.path, "r", encoding="utf-8") as f:
                    content = f.read()
                files_content.append(f"íŒŒì¼ëª…: {element.name}\në‚´ìš©:\n{content}\n")
            except UnicodeDecodeError:
                # Try binary file
                try:
                    with open(element.path, "rb") as f:
                        content = f.read()
                    files_content.append(f"íŒŒì¼ëª…: {element.name}\n(ë°”ì´ë„ˆë¦¬ íŒŒì¼, {len(content)} bytes)\n")
                except Exception as e:
                    files_content.append(f"íŒŒì¼ëª…: {element.name}\nì˜¤ë¥˜: {str(e)}\n")
            except Exception as e:
                files_content.append(f"íŒŒì¼ëª…: {element.name}\nì˜¤ë¥˜: {str(e)}\n")
    
    return "\n---\n".join(files_content)


if __name__ == "__main__":
    # This is handled by chainlit CLI
    pass
